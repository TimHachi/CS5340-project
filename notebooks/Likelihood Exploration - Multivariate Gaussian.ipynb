{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "imported-jurisdiction",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fossil-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "from random import randrange\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-slide",
   "metadata": {},
   "source": [
    "## Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "known-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZOOM_SIZE = 1\n",
    "SIGMA = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "statutory-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(img, width):\n",
    "    x, y = img.size\n",
    "    matrix = width\n",
    "\n",
    "    x1 = randrange(0, x - matrix)\n",
    "    y1 = randrange(0, y - matrix)\n",
    "    return img.crop((x1, y1, x1 + matrix, y1 + matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ultimate-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folderpath, limit, img_size_crop):\n",
    "    image_paths = sorted(glob.glob(folderpath))\n",
    "    img_arr = []\n",
    "    for img_path in image_paths[:limit]:\n",
    "        print('Loading', img_path)\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        image = random_crop(image, img_size_crop)\n",
    "        image = np.asarray(image)\n",
    "        # summarize shape of the pixel array\n",
    "        img_arr.append(image)\n",
    "    \n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "reduced-cedar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../dataset/DIV2K_valid_HR/0801.png\n",
      "Loading ../dataset/DIV2K_valid_HR/0802.png\n",
      "Loading ../dataset/DIV2K_valid_HR/0803.png\n",
      "Loading ../dataset/DIV2K_valid_HR/0804.png\n",
      "Loading ../dataset/DIV2K_valid_HR/0805.png\n",
      "Loading ../dataset/DIV2K_valid_HR/0806.png\n",
      "Loading ../dataset/DIV2K_valid_HR/0807.png\n",
      "Loading ../dataset/DIV2K_valid_HR/0808.png\n",
      "Loading ../dataset/DIV2K_valid_HR/0809.png\n",
      "Loading ../dataset/DIV2K_valid_HR/0810.png\n"
     ]
    }
   ],
   "source": [
    "hr_img_arr = load_images(\"../dataset/DIV2K_valid_HR/*.png\", 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "coral-perth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../dataset/DIV2K_valid_LR_bicubic/x2/0801x2.png\n",
      "Loading ../dataset/DIV2K_valid_LR_bicubic/x2/0802x2.png\n",
      "Loading ../dataset/DIV2K_valid_LR_bicubic/x2/0803x2.png\n",
      "Loading ../dataset/DIV2K_valid_LR_bicubic/x2/0804x2.png\n",
      "Loading ../dataset/DIV2K_valid_LR_bicubic/x2/0805x2.png\n",
      "Loading ../dataset/DIV2K_valid_LR_bicubic/x2/0806x2.png\n",
      "Loading ../dataset/DIV2K_valid_LR_bicubic/x2/0807x2.png\n",
      "Loading ../dataset/DIV2K_valid_LR_bicubic/x2/0808x2.png\n",
      "Loading ../dataset/DIV2K_valid_LR_bicubic/x2/0809x2.png\n",
      "Loading ../dataset/DIV2K_valid_LR_bicubic/x2/0810x2.png\n"
     ]
    }
   ],
   "source": [
    "lr_img_arr = load_images(\"../dataset/DIV2K_valid_LR_bicubic/x2/*.png\", 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "separated-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_img_arr = [e[::ZOOM_SIZE].flatten().reshape(1, -1) for e in lr_img_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "sexual-kansas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_img_arr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "minor-specification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_img_arr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "spatial-dancing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lr_img_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-picture",
   "metadata": {},
   "source": [
    "## Downsample and Blur HR Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "municipal-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matlab_style_gauss2D(shape=(3,3),sigma=0.5):\n",
    "    \"\"\"\n",
    "    2D gaussian mask - should give the same result as MATLAB's\n",
    "    fspecial('gaussian',[shape],[sigma])\n",
    "    \"\"\"\n",
    "    m,n = [(ss-1.)/2. for ss in shape]\n",
    "    y,x = np.ogrid[-m:m+1,-n:n+1]\n",
    "    h = np.exp( -(x*x + y*y) / (2.*sigma*sigma) )\n",
    "    h[ h < np.finfo(h.dtype).eps*h.max() ] = 0\n",
    "    sumh = h.sum()\n",
    "    if sumh != 0:\n",
    "        h /= sumh\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "skilled-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "approved-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_pipeline.obs_for_SR import obs_for_SR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-messenger",
   "metadata": {},
   "source": [
    "Run downsampling + blur on all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "strategic-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_lr_img_arr = np.array([\n",
    "    obs_for_SR(\n",
    "        image, \n",
    "        matlab_style_gauss2D((7,7), 2),\n",
    "        SIGMA, \n",
    "        ZOOM_SIZE\n",
    "    ).flatten().reshape(1, -1) for image in hr_img_arr\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "existing-hygiene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_lr_img_arr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "divine-commonwealth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 100)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_lr_img_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-stocks",
   "metadata": {},
   "source": [
    "## Multivariate Gaussian Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "complicated-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-general",
   "metadata": {},
   "source": [
    "ùúáÃÇ = 1/ùëö ‚àëùê±(ùê¢) = ùê±¬Ø<br>\n",
    "Œ£ÃÇ =1/ùëö‚àë(ùê±(ùê¢)‚àíùúáÃÇ ) (ùê±(ùê¢)‚àíùúáÃÇ )ùëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "rural-graphic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_lr_img_arr.reshape(10, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "digital-uzbekistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1) (100, 100)\n"
     ]
    }
   ],
   "source": [
    "mu = np.mean(transformed_lr_img_arr, axis=0).reshape(-1, 1)\n",
    "cov = np.mean([np.dot((lr_img - mu), (lr_img - mu).T) for lr_img in transformed_lr_img_arr], axis=0)\n",
    "print(mu.shape, cov.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "latin-ceremony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-bathroom",
   "metadata": {},
   "source": [
    "Calculate for sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "weighted-luxembourg",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0779787013733026e-07"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvn.pdf(lr_img_arr[0], mean=mu.reshape(-1), cov=cov, allow_singular=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
